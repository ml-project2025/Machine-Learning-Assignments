# -*- coding: utf-8 -*-
"""
Ù…Ø´Ø±ÙˆØ¹ Ù…Ø¨Ø³Ø· Ù„Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…ÙƒØªÙˆØ¨Ø© Ø¨Ø®Ø· Ø§Ù„ÙŠØ¯ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª MNIST
ÙŠØ´Ù…Ù„:
- ØªØ­Ù…ÙŠÙ„ ÙˆØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
- Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Dense Ø¨Ø³ÙŠØ·
- Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ CNN
- ØªØ¯Ø±ÙŠØ¨ ÙˆØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ÙŠÙ†
- Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
- Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨ØµÙˆØ±Ø© Ø¬Ø¯ÙŠØ¯Ø© (Ù…Ù† Ù…Ù„Ù Ø®Ø§Ø±Ø¬ÙŠ)
- Ø±Ø³Ù… Ù…Ù†Ø­Ù†ÙŠØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (Accuracy / Loss)
"""

import numpy as np
import matplotlib.pyplot as plt
import cv2
from sklearn.metrics import classification_report
from tensorflow.keras import datasets, layers, models
from tensorflow.keras.utils import to_categorical

# -------------------------------
# 1. ØªØ­Ù…ÙŠÙ„ ÙˆØªØ¬Ù‡ÙŠØ² Ø¨ÙŠØ§Ù†Ø§Øª MNIST
# -------------------------------
(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()

# ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ… Ø¥Ù„Ù‰ [0,1])
x_train = x_train.astype("float32") / 255.0
x_test = x_test.astype("float32") / 255.0

# Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ÙƒÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø´Ø¨ÙƒØ© CNN (28x28x1)
x_train_cnn = np.expand_dims(x_train, -1)
x_test_cnn = np.expand_dims(x_test, -1)

# ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªØ³Ù…ÙŠØ§Øª Ø¥Ù„Ù‰ one-hot
y_train_cat = to_categorical(y_train, 10)
y_test_cat = to_categorical(y_test, 10)

# ØªÙ‚Ø³ÙŠÙ… Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (Training / Validation)
x_val = x_train_cnn[-10000:]
y_val = y_train_cat[-10000:]
x_train_cnn = x_train_cnn[:-10000]
y_train_cat = y_train_cat[:-10000]

# -------------------------------
# 2. Ù†Ù…ÙˆØ°Ø¬ Dense Ø¨Ø³ÙŠØ·
# -------------------------------
dense_model = models.Sequential([
    layers.Flatten(input_shape=(28, 28, 1)),
    layers.Dense(128, activation='relu'),
    layers.Dense(10, activation='softmax')
])

dense_model.compile(optimizer='adam',
                    loss='categorical_crossentropy',
                    metrics=['accuracy'])

print("\n--- ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Dense ---")
history_dense = dense_model.fit(
    x_train_cnn, y_train_cat,
    epochs=5,
    batch_size=128,
    validation_data=(x_val, y_val),
    verbose=2
)

# -------------------------------
# 3. Ù†Ù…ÙˆØ°Ø¬ CNN
# -------------------------------
cnn_model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])

cnn_model.compile(optimizer='adam',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

print("\n--- ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ CNN ---")
history_cnn = cnn_model.fit(
    x_train_cnn, y_train_cat,
    epochs=5,
    batch_size=128,
    validation_data=(x_val, y_val),
    verbose=2
)

# -------------------------------
# 4. Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
# -------------------------------
print("\n--- ØªÙ‚ÙŠÙŠÙ… Ù†Ù…ÙˆØ°Ø¬ Dense ---")
y_pred_dense = dense_model.predict(x_test_cnn, verbose=0)
print(classification_report(y_test, np.argmax(y_pred_dense, axis=1)))

print("\n--- ØªÙ‚ÙŠÙŠÙ… Ù†Ù…ÙˆØ°Ø¬ CNN ---")
y_pred_cnn = cnn_model.predict(x_test_cnn, verbose=0)
print(classification_report(y_test, np.argmax(y_pred_cnn, axis=1)))

# -------------------------------
# 5. Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£ÙØ¶Ù„ (CNN Ø¹Ø§Ø¯Ø©Ù‹)
# -------------------------------
cnn_model.save("mnist_cnn_model.h5")
print("\nâœ… ØªÙ… Ø­ÙØ¸ Ù†Ù…ÙˆØ°Ø¬ CNN ÙÙŠ Ø§Ù„Ù…Ù„Ù mnist_cnn_model.h5")

# -------------------------------
# 6. Ø±Ø³Ù… Ù…Ù†Ø­Ù†ÙŠØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
# -------------------------------
def plot_history(history, title):
    """Ø¯Ø§Ù„Ø© Ù„Ø±Ø³Ù… Accuracy Ùˆ Loss"""
    plt.figure(figsize=(12, 4))

    # Ø§Ù„Ø¯Ù‚Ø©
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Train Acc')
    plt.plot(history.history['val_accuracy'], label='Val Acc')
    plt.title(f'{title} - Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()

    # Ø§Ù„Ø®Ø³Ø§Ø±Ø©
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Val Loss')
    plt.title(f'{title} - Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    plt.show()

print("\nğŸ“Š Ù…Ù†Ø­Ù†ÙŠØ§Øª ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Dense")
plot_history(history_dense, "Dense Model")

print("\nğŸ“Š Ù…Ù†Ø­Ù†ÙŠØ§Øª ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ CNN")
plot_history(history_cnn, "CNN Model")

# -------------------------------
# 7. Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨ØµÙˆØ±Ø© Ø¬Ø¯ÙŠØ¯Ø©
# -------------------------------
def predict_new_image(img_path):
    """ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø© Ø®Ø§Ø±Ø¬ÙŠØ© (28x28 Ø£Ø¨ÙŠØ¶ ÙˆØ£Ø³ÙˆØ¯) ÙˆØ§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù‡Ø§"""
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    img = cv2.resize(img, (28, 28))
    img = img.astype("float32") / 255.0
    img = np.expand_dims(img, axis=(0, -1))  # Ø§Ù„Ø´ÙƒÙ„ (1,28,28,1)
    
    prediction = cnn_model.predict(img, verbose=0)
    return np.argmax(prediction)

# Ù…Ø«Ø§Ù„: Ø¶Ø¹ ØµÙˆØ±Ø© Ø±Ù‚Ù… Ø¨Ø§Ø³Ù… "digit.png" ÙÙŠ Ù†ÙØ³ Ø§Ù„Ù…Ø¬Ù„Ø¯
# print("Ø§Ù„Ø±Ù‚Ù… Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ Ù‡Ùˆ:", predict_new_image("digit.png"))

